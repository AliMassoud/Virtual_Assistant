{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Ali Massoud\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosToLetter = {\"ADV\":\"r\",\n",
    "              \"VERB\":\"v\",\n",
    "              \"ADJ\":\"a\", \n",
    "              \"NOUN\":\"n\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization (text):\n",
    "    toLower = text.lower()\n",
    "    toLower = re.sub(r'\\d+','',toLower)\n",
    "    Tokenized_Sentence = sent_tokenize(toLower)\n",
    "    stringResult= \"\"\n",
    "    for i in range(len(Tokenized_Sentence)):\n",
    "        Tokenized_Sentence[i] = re.sub(r\"([^a-z\\'])+\", ' ', Tokenized_Sentence[i])\n",
    "        Tokenized_Sentence[i] = re.sub(r\"\\'\",\"\",Tokenized_Sentence[i])\n",
    "       \n",
    "        \n",
    "    WordTokenized = []\n",
    "    for i in range(len(Tokenized_Sentence)):\n",
    "        WordList = word_tokenize(Tokenized_Sentence[i])\n",
    "        for j in WordList:\n",
    "            WordTokenized.append(j)\n",
    "\n",
    "    no_StopWords = []\n",
    "    stopword = set(stopwords.words('english'))\n",
    "    for word in WordTokenized:\n",
    "        if(word not in stopword):\n",
    "            no_StopWords.append(word)\n",
    "\n",
    "    Tuples = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    Tuples = nltk.pos_tag(no_StopWords, tagset = 'universal')\n",
    "    ResultLemmaVerbs = []\n",
    "    for i in Tuples:\n",
    "        if(i[1] in PosToLetter.keys()):\n",
    "            stringResult += lemmatizer.lemmatize(i[0], pos=PosToLetter[i[1]])+ \" \"\n",
    "        else: stringResult += i[0]+\" \"\n",
    "            \n",
    "\n",
    "    return stringResult[:-1] #to remove last space, also stringResult is just to get the whole text as a string so that it\n",
    "                             #can be fed to module 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tennis racket sport play individually single opponent single two team two player double player use\n"
     ]
    }
   ],
   "source": [
    "listOfFiles = [\"1.txt\",\"2.txt\",\"3.txt\",\"4.txt\",\"5.txt\",\"6.txt\",\"7.txt\",\"8.txt\",\"9.txt\",\"10.txt\"]\n",
    "documents= [open(f,encoding=\"utf8\").read() for f in listOfFiles]\n",
    "\n",
    "listOfNormText = []\n",
    "for i in range(len(listOfFiles)):\n",
    "    Norm = Normalization(documents[i])\n",
    "    listOfNormText.append(Norm)\n",
    "    \n",
    "print(listOfNormText[0][0:98]) #this is a sample of the first text after normalizing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckGreeting(input):\n",
    "    my_Greetings = [\"hello bot\", \"hey bot\", \"hay you\", \"hello friend\", \"good morning bot\", \"good afternoon bot\", \"hi friend\",\"hey friend\"]\n",
    "    Response_bot = [\"hey captain!\", \"hey boss\", \"Hola boss\", \"Hello!\", \"Hello friend\"]\n",
    "    if(input in my_Greetings):\n",
    "        return(random.choice(Response_bot));\n",
    "    else: return(\"I am sorry, I do not understand what you are asking me, please try again\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CheckGreeting(\"hello bot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the similarity degree (probability) to the input to each corresponding text.\n",
    "def get_tf_idf_input_similarity(FullList, UserInput):\n",
    "    Doc_List = []\n",
    "    for text in documents:\n",
    "        Doc_List.append(Normalization(text))\n",
    "    TFIDF_List = TfidfVectorizer(use_idf=True,ngram_range=(1,1)).fit_transform(Doc_List)\n",
    "    TFIDF_UserInput = TfidfVectorizer().fit(Doc_List)\n",
    "    TFIDF_UserInput = TFIDF_UserInput.transform([Normalization(UserInput)])\n",
    "    Sim = cosine_similarity(TFIDF_UserInput, TFIDF_List).flatten()\n",
    "    return Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# get_tf_idf_input_similarity([listOfNormText[0],listOfNormText[1],listOfNormText[2],listOfNormText[3],listOfNormText[4],listOfNormText[5]\n",
    "#                              ,listOfNormText[6],listOfNormText[7],listOfNormText[8],listOfNormText[9]],\"tell me about the tennis grand slam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_max_similarity(Input):\n",
    "    list_of_relevance = get_tf_idf_input_similarity([listOfNormText[0],listOfNormText[1],listOfNormText[2],listOfNormText[3],listOfNormText[4],listOfNormText[5]\n",
    "                              ,listOfNormText[6],listOfNormText[7],listOfNormText[8],listOfNormText[9]],Input)\n",
    "    indexOfMax = 0\n",
    "    maxproba=0.01\n",
    "    for i in range(len(list_of_relevance)):\n",
    "        if (list_of_relevance[i] > maxproba):\n",
    "            indexOfMax = i\n",
    "            maxproba = list_of_relevance[i]\n",
    "    if (maxproba==0.01):\n",
    "        return \"I am sorry, I do not understand what you are asking me\"\n",
    "    else:\n",
    "        return documents[indexOfMax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_the_max_similarity(\"How is tennis played?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "from gtts import gTTS\n",
    "import playsound\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module 4 part 1\n",
    "def Recognize_from_prerecorded_audio():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.WavFile(\"Assignmentaudio.wav\") as source:  \n",
    "        audio = r.record(source)\n",
    "    \n",
    "    try:\n",
    "        audioText = r.recognize_google(audio)  \n",
    "        output= CheckGreeting(audioText.lower())+\", \"+get_the_max_similarity(audioText.lower())\n",
    "    except LookupError:\n",
    "        output = \"I Could not understand the audio, please try again\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module_4_part_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module 4 part 2\n",
    "def Recognize_from_Microphone():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        audio = r.listen(source)                  \n",
    "\n",
    "    try:\n",
    "        audioText=r.recognize_google(audio)\n",
    "    except LookupError:\n",
    "        print(\"Could not understand audio, please try again\")\n",
    "    return get_the_max_similarity(audioText.lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_to_speech(answer):\n",
    "    Our_audio = gTTS(text=answer,lang='en')\n",
    "    file = 'demo.mp3'\n",
    "    Our_audio.save(file)\n",
    "    playsound.playsound(file)\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you do not have a mp3 file in the same directory already called demo.mp3 so you do not\n",
    "# face any problems when you run this code.\n",
    "def Our_Speech_Bot():\n",
    "    stop = False\n",
    "    while (True):\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            audio = r.listen(source)\n",
    "        try:\n",
    "            audioText=r.recognize_google(audio)\n",
    "            print(\"You said \" + audioText)\n",
    "        except LookupError:\n",
    "            print(\"Could not understand audio, Please try again\")\n",
    "        first_reply = CheckGreeting(audioText.lower())\n",
    "        if (first_reply!=\"I am sorry, I do not understand what you are asking me, please try again\"):\n",
    "            ans = first_reply\n",
    "        elif audioText==\"bye\" or audioText==\"bye bobby\" or audioText==\"goodbye\":\n",
    "            ans=\"Bye Ali & Ahmad\"\n",
    "            stop=True\n",
    "        else:\n",
    "            ans = get_the_max_similarity(audioText.lower())\n",
    "        print(ans)\n",
    "        Text_to_speech(ans) #once you ask a question it is taking around 2 seconds to start answering as an audio\n",
    "                            #please be please be patient ^_^\n",
    "        if stop==True:\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You said hello friend\n",
      "Hello!\n",
      "You said hi\n",
      "I am sorry, I do not understand what you are asking me\n",
      "You said bye\n",
      "Bye Ali & Ahmad\n"
     ]
    }
   ],
   "source": [
    "# Once it finishes answering you can ask your next question ^_^\n",
    "\n",
    "Our_Speech_Bot()\n",
    "# Tennis is played on a rectangular, flat surface.\n",
    "\n",
    "# Some questions were prepared:\n",
    "\n",
    "# 1- What is Tennis?\n",
    "# 2- Is Tennis an Olympic sport?\n",
    "# 3- What is the lawn mower invention?\n",
    "# 4- What are the components of the Tennis racket?\n",
    "# 5- What does the receiver player do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
